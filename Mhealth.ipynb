{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\SUDHIR\n",
      "[nltk_data]     KUTRE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#printing stopwords\n",
    "nltk.download('stopwords')\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id                                               text        class  \\\n",
      "0  302034  I made a grave mistake I donât remember the ...  non-suicide   \n",
      "1  302035  What series you like. I have watched all my fa...  non-suicide   \n",
      "2  302036  Guys I did it! I lost my virginity but it wasn...  non-suicide   \n",
      "3  302037  This guy like me or no? So, basically I have t...  non-suicide   \n",
      "4  302040  I have no hopeMy ex boyfriend cheated on me an...      suicide   \n",
      "\n",
      "  Unnamed: 3 Unnamed: 4 Unnamed: 5 Unnamed: 6 Unnamed: 7  \n",
      "0        NaN        NaN        NaN        NaN        NaN  \n",
      "1        NaN        NaN        NaN        NaN        NaN  \n",
      "2        NaN        NaN        NaN        NaN        NaN  \n",
      "3        NaN        NaN        NaN        NaN        NaN  \n",
      "4        NaN        NaN        NaN        NaN        NaN  \n"
     ]
    }
   ],
   "source": [
    "#data preprocessing\n",
    "mh_data=pd.read_csv('Sdata2.csv',encoding='unicode_escape')\n",
    "#printing first five lines\n",
    "print(mh_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id               69\n",
      "text            107\n",
      "class           129\n",
      "Unnamed: 3    30928\n",
      "Unnamed: 4    30931\n",
      "Unnamed: 5    30932\n",
      "Unnamed: 6    30932\n",
      "Unnamed: 7    30932\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#checking for missing values\n",
    "print(mh_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id            0\n",
      "text          0\n",
      "class         0\n",
      "Unnamed: 3    0\n",
      "Unnamed: 4    0\n",
      "Unnamed: 5    0\n",
      "Unnamed: 6    0\n",
      "Unnamed: 7    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#replacing missing values with null string\n",
    "mh_data=mh_data.fillna('')\n",
    "print(mh_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        non-suicide\n",
      "1        non-suicide\n",
      "2        non-suicide\n",
      "3        non-suicide\n",
      "4            suicide\n",
      "            ...     \n",
      "30928    non-suicide\n",
      "30929    non-suicide\n",
      "30930    non-suicide\n",
      "30931        suicide\n",
      "30932    non-suicide\n",
      "Name: class, Length: 30933, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#separating feature and target\n",
    "X=mh_data.drop(columns='class',axis=1)\n",
    "Y=mh_data['class']\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        I made a grave mistake I donât remember the ...\n",
      "1        What series you like. I have watched all my fa...\n",
      "2        Guys I did it! I lost my virginity but it wasn...\n",
      "3        This guy like me or no? So, basically I have t...\n",
      "4        I have no hopeMy ex boyfriend cheated on me an...\n",
      "                               ...                        \n",
      "30928    If you don't like rock then your not going to ...\n",
      "30929    You how you can tell i have so many friends an...\n",
      "30930    pee probably tastes like salty teaðð¦â¼ï...\n",
      "30931    The usual stuff you find hereI'm not posting t...\n",
      "30932    I still haven't beaten the first boss in Hollo...\n",
      "Name: text, Length: 30933, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(mh_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        made grave mistak rememb post know someth lgbt...\n",
      "1        seri like watch favorit seri multipl time wond...\n",
      "2        guy lost virgin cool thought pp went soft minu...\n",
      "3        guy like basic friend keep give littl hint lik...\n",
      "4        hopemi ex boyfriend cheat gave genit herp hard...\n",
      "                               ...                        \n",
      "30928    like rock go get anyth go http musictast space...\n",
      "30929    tell mani friend lone everyth depriv pre bough...\n",
      "30930    pee probabl tast like salti tea someon drank p...\n",
      "30931    usual stuff find herei post sympathi piti know...\n",
      "30932    still beaten first boss hollow knight fought t...\n",
      "Name: text, Length: 30933, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#stemming\n",
    "port_stem=PorterStemmer()\n",
    "def stemming(content):\n",
    "    stemmed_content=re.sub('[^a-zA-Z]',' ',content)\n",
    "    stemmed_content=stemmed_content.lower()\n",
    "    stemmed_content=stemmed_content.split()\n",
    "    stemmed_content=[port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]\n",
    "    stemmed_content=' '.join(stemmed_content)\n",
    "    return stemmed_content\n",
    "mh_data['text']=mh_data['text'].apply(stemming)\n",
    "print(mh_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['made grave mistak rememb post know someth lgbt commun made comment tri say someth along line straight like thought gay person whatev hell want came across homophob lost know care whether peopl get exactli word well'\n",
      " 'seri like watch favorit seri multipl time wonder guy favorit netflix mabi calm mabi watch brand new netflix seri'\n",
      " 'guy lost virgin cool thought pp went soft minut fuck' ...\n",
      " 'pee probabl tast like salti tea someon drank pee confirm'\n",
      " 'usual stuff find herei post sympathi piti know far wors situat mine want get stuff seem life point everyth done life ruin quit isol everyon even famili even like tell famili would help consid psychot probabl right know sens fuck univers want think seem like univers fuck made know made fuck think know want get peopl tri help went rough patch got tough done tough life tough look around famili sinc youngest seen ridicul shit happen fuck post area first time felt like tri take life bitch know mean serious cruel joke play despis life want know would like end even fuck whenev around friend would put macho tough guy like noth hurt kept everyth bottl anyth life complain option make better good would come fail colleg probabl never get back track light call light end tunnel get smaller day'\n",
      " 'still beaten first boss hollow knight fought time alway die realli earli fight terribl game']\n",
      "['non-suicide' 'non-suicide' 'non-suicide' ... 'non-suicide' 'suicide'\n",
      " 'non-suicide']\n"
     ]
    }
   ],
   "source": [
    "#X has features and Y has labes\n",
    "X=mh_data['text'].values\n",
    "Y=mh_data['class'].values\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30933,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30933,)\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 33346)\t0.16764732931605258\n",
      "  (0, 32969)\t0.20013566234915206\n",
      "  (0, 32927)\t0.16813274028133982\n",
      "  (0, 32847)\t0.12860531529127242\n",
      "  (0, 32561)\t0.07493371584028177\n",
      "  (0, 30598)\t0.09616400940755265\n",
      "  (0, 29776)\t0.11056144127731336\n",
      "  (0, 28207)\t0.18697310766669029\n",
      "  (0, 27382)\t0.22563559355654228\n",
      "  (0, 25706)\t0.10499459779454338\n",
      "  (0, 24693)\t0.15744866718336942\n",
      "  (0, 23015)\t0.12062648687212743\n",
      "  (0, 22282)\t0.11710097501358104\n",
      "  (0, 22177)\t0.09234323013754775\n",
      "  (0, 19071)\t0.19111574650662655\n",
      "  (0, 17964)\t0.25139820058018997\n",
      "  (0, 17695)\t0.14116393706275365\n",
      "  (0, 17301)\t0.1947647240016349\n",
      "  (0, 17256)\t0.07267108614971887\n",
      "  (0, 17106)\t0.27394605424338037\n",
      "  (0, 16550)\t0.16030322715683049\n",
      "  (0, 14030)\t0.2550972372929163\n",
      "  (0, 13456)\t0.16037074750533517\n",
      "  (0, 12596)\t0.2712413080802721\n",
      "  (0, 12046)\t0.07943307302901155\n",
      "  :\t:\n",
      "  (30931, 5587)\t0.052526327876709016\n",
      "  (30931, 5546)\t0.06661680997928646\n",
      "  (30931, 4323)\t0.0562801442275847\n",
      "  (30931, 3629)\t0.0887660890769362\n",
      "  (30931, 3211)\t0.08481780824092443\n",
      "  (30931, 2999)\t0.04990325273186466\n",
      "  (30931, 2367)\t0.04913960972725895\n",
      "  (30931, 1821)\t0.10930152568282914\n",
      "  (30931, 1752)\t0.09381672962382472\n",
      "  (30931, 1535)\t0.047197256890325515\n",
      "  (30932, 29949)\t0.11993230539764974\n",
      "  (30932, 29377)\t0.24243652701458282\n",
      "  (30932, 28091)\t0.15327404689263016\n",
      "  (30932, 24301)\t0.1286805402701518\n",
      "  (30932, 16531)\t0.4325065339381604\n",
      "  (30932, 13970)\t0.3553185783774267\n",
      "  (30932, 11814)\t0.2112908154464833\n",
      "  (30932, 11276)\t0.33312830933080534\n",
      "  (30932, 10851)\t0.17382632913412024\n",
      "  (30932, 10673)\t0.22495717838155796\n",
      "  (30932, 8831)\t0.26674533758072816\n",
      "  (30932, 7652)\t0.14447165150172822\n",
      "  (30932, 3610)\t0.3161373319325266\n",
      "  (30932, 2740)\t0.3461828884634764\n",
      "  (30932, 1074)\t0.1588263878150963\n"
     ]
    }
   ],
   "source": [
    "#converting textual data to numberical data\n",
    "vectorizer=TfidfVectorizer()\n",
    "vectorizer.fit(X)\n",
    "X=vectorizer.transform(X)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the labels values into numberics\n",
    "#from sklearn import preprocessing\n",
    "#label_encoder=preprocessing.LabelEncoder()\n",
    "#mh_data['class']=label_encoder.fit_transform(mh_data['class'])\n",
    "#mh_data['class'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#splitting dataset into training and testing\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train,X_test,Y_train,Y_test\u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mstratify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2441\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2437\u001b[0m         CVClass \u001b[38;5;241m=\u001b[39m ShuffleSplit\n\u001b[0;32m   2439\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m-> 2441\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstratify\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2443\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2444\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m   2445\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2446\u001b[0m     )\n\u001b[0;32m   2447\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1600\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m   1571\u001b[0m \n\u001b[0;32m   1572\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;124;03mto an integer.\u001b[39;00m\n\u001b[0;32m   1598\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m-> 1600\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_indices(X, y, groups):\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m train, test\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1940\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit._iter_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1938\u001b[0m class_counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mbincount(y_indices)\n\u001b[0;32m   1939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmin(class_counts) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m-> 1940\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1941\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe least populated class in y has only 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1942\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m member, which is too few. The minimum\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1943\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m number of groups for any class cannot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1944\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be less than 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1945\u001b[0m     )\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m<\u001b[39m n_classes:\n\u001b[0;32m   1948\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1949\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe train_size = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m should be greater or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1950\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequal to the number of classes = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_train, n_classes)\n\u001b[0;32m   1951\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "#splitting dataset into training and testing\n",
    "X_train,X_test,Y_train,Y_test= train_test_split(X,Y,test_size=0.2,stratify=Y,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries to fit the model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#training logistic regression model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m=\u001b[39mLogisticRegression()\n\u001b[1;32m----> 3\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m,Y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "#training logistic regression model\n",
    "model=LogisticRegression()\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluating accuracy score on training data\n",
    "X_train_prediction=model.predict(X_train)\n",
    "training_data_accuracy=accuracy_score(X_train_prediction,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy score of the training data \",training_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating accuarcy score on the testing data\n",
    "X_test_prediction=model.predict(X_test)\n",
    "testing_data_accuracy=accuracy_score(X_test_prediction,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy score of the testing data \",testing_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a predictive system\n",
    "X_new=X_test[55]\n",
    "prediction=model.predict(X_new)\n",
    "print(prediction)\n",
    "print(Y_test[55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
